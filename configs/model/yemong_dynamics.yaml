_target_: boost_and_broadside.models.yemong.scaffolds.YemongDynamics

d_model: 256
n_layers: 6
n_heads: 4
learning_rate: 1e-4

# Action Embedding Dimension (per component)
# Total action embedding will be 3 * action_embed_dim
action_embed_dim: 16

scheduler:
  type: "warmup_constant"
  warmup:
    steps: 500
    start_lr: 1e-7

spatial_layer:
  _target_: boost_and_broadside.models.components.layers.attention.RelationalAttention
  d_model: ${model.d_model}
  n_heads: ${model.n_heads}

# Loss Configuration
loss:
  _target_: boost_and_broadside.models.components.losses.CompositeLoss
  loss_type: ${model.loss_type}
  losses:
    - _target_: boost_and_broadside.models.components.losses.StateLoss
      weight: ${model.lambda_state}
    - _target_: boost_and_broadside.models.components.losses.ActionLoss
      weight: ${model.lambda_actions}
    - _target_: boost_and_broadside.models.components.losses.ValueLoss
      weight: ${model.lambda_value}
    - _target_: boost_and_broadside.models.components.losses.RewardLoss
      weight: ${model.lambda_reward}
    - _target_: boost_and_broadside.models.components.losses.PairwiseRelationalLoss
      weight: ${model.lambda_pairwise}

# Loss weights
lambda_state: 1.0
lambda_actions: 1.0
lambda_value: 1.0
lambda_reward: 1.0
lambda_pairwise: 0.1

# Pairwise Relational Targets (N x N)
use_pairwise_targets: false

# Loss Type (fixed or uncertainty)
loss_type: "fixed"

# Reward Decomposition
num_reward_components: 5
