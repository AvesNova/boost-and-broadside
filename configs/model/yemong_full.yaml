_target_: boost_and_broadside.models.yemong.scaffolds.YemongFull

d_model: 256
n_layers: 6
n_heads: 4
input_dim: 9       # Adjust based on Tokenizer/Dataset
target_dim: 9      # Same as input usually
action_dim: 12      # 3 Power + 7 Turn + 2 Shoot
learning_rate: 1e-4

scheduler:
  type: "warmup_constant"
  warmup:
    steps: 1000
    start_lr: 1e-7

loss_type: "uncertainty"

spatial_layer:
  _target_: boost_and_broadside.models.components.layers.attention.RelationalAttention
  d_model: ${model.d_model}
  n_heads: ${model.n_heads}

# Training params moved here for context, but usually in 'train'
lambda_state: 1.0
lambda_actions: 0.15
lambda_value: 0.5
lambda_reward: 10.0
