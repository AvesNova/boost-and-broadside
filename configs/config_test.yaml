mode: collect

environment:
  render_mode: "none"
  world_size: [1200, 800]
  memory_size: 2
  max_ships: 8
  agent_dt: 0.1
  physics_dt: 0.05
  random_positioning: true
  random_speed: true
  random_initialization: true

agents:
  scripted:
    agent_type: scripted
    agent_config:
      max_shooting_range: 500.0
      angle_threshold: 5.0
      bullet_speed: 500.0
      target_radius: 10.0
      radius_multiplier: 1.5
      world_size: [1200, 800]

collect:
  teams: [scripted, scripted]
  episodes_per_mode:
    "1v1": 4
    "2v2": 4
    "3v3": 4
    "4v4": 4
  output_dir: "data/test_data"
  num_workers: 2
  save_frequency: 2
  render_mode: "none"
  max_episode_length: 512
  random_action_prob: 0.05

train:
  run_collect: false
  run_bc: false
  run_world_model: false
  run_rl: false

  use_bc: true
  use_rl: true
  bc_data_path: "data/test_data/20260114_102934/aggregated_data.pkl"
  
  model:
    transformer:
      token_dim: 12
      embed_dim: 64
      num_heads: 4
      num_layers: 3
      max_ships: 8
      num_actions: 6
      dropout: 0.1
      use_layer_norm: true

  bc:
    learning_rate: 0.001
    batch_size: 128
    epochs: 50
    validation_split: 0.2
    early_stopping_patience: 10
    policy_weight: 1.0
    value_weight: 0.5

  rl:
    learning_rate: 0.0003
    n_steps: 4096
    batch_size: 128
    n_epochs: 10
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.01
    vf_coef: 0.5
    max_grad_norm: 0.5

world_model:
  embed_dim: 64
  n_layers: 2
  n_heads: 2
  context_len: 96
  n_ships: 8
  mask_ratio: 0.15
  noise_scale: 0.1
  input_noise_ratio: 0.1
  input_noise_scale: 0.1
  learning_rate: 0.001
  epochs: 3
  
  # Mixed Batch Training
  short_batch_size: 16
  long_batch_size: 4
  short_batch_len: 32
  long_batch_len: 128
  batch_ratio: 4
  
  rope_base: 10000.0
  rope_max_seq_len: 256

  rollout:
    enabled: true
    start_epoch: 1
    max_len_start: 1
    max_len_end: 2
    ramp_epochs: 2

