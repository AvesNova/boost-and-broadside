mode: collect

environment:
  render_mode: "none"
  world_size: [1200, 800]
  memory_size: 2
  max_ships: 8
  agent_dt: 0.04
  physics_dt: 0.02

agents:
  scripted:
    agent_type: scripted
    agent_config:
      max_shooting_range: 500.0
      angle_threshold: 5.0
      bullet_speed: 500.0
      target_radius: 10.0
      radius_multiplier: 1.5
      world_size: [1200, 800]

collect:
  teams: [scripted, scripted]
  episodes_per_mode:
    "1v1": 2
    "2v2": 2
    "3v3": 2
    "4v4": 2
  output_dir: "data/bc_pretraining"
  num_workers: 2
  save_frequency: 4
  render_mode: "none"
  max_episode_length: 512

train:
  use_bc: true
  use_rl: true
  bc_data_path: ""
  
  model:
    transformer:
      token_dim: 12
      embed_dim: 64
      num_heads: 4
      num_layers: 3
      max_ships: 8
      num_actions: 6
      dropout: 0.1
      use_layer_norm: true

  bc:
    learning_rate: 0.001
    batch_size: 128
    epochs: 50
    validation_split: 0.2
    early_stopping_patience: 10
    policy_weight: 1.0
    value_weight: 0.5

  rl:
    learning_rate: 0.0003
    n_steps: 4096
    batch_size: 128
    n_epochs: 10
    gamma: 0.99
    gae_lambda: 0.95
    clip_range: 0.2
    ent_coef: 0.01
    vf_coef: 0.5
    max_grad_norm: 0.5
