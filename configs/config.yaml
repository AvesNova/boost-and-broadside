defaults:
  - _self_
  - model: yemong_full
  - train: ppo

mode: play
team1: scripted
team2: scripted
human_player: false
seed: 42

wandb:
  enabled: true
  project: "boost-and-broadside"
  entity: null
  name: null
  group: null
  mode: "online"
  log_frequency: 50

profiler:
  enabled: false
  wait: 32
  warmup: 4
  active: 5
  repeat: 1
  schedule_type: "skip_first"

environment:
  render_mode: "human"
  world_size: [1024, 1024]
  memory_size: 2
  max_ships: 8
  agent_dt: 0.04
  physics_dt: 0.02
  random_positioning: true
  random_speed: true
  random_initialization: true
  backend: "cpu"

agents:
  scripted:
    agent_type: scripted
    agent_config:
      max_shooting_range: 500.0
      angle_threshold: 5.0
      bullet_speed: 500.0
      target_radius: 10.0
      radius_multiplier: 1.5
      world_size: [1024, 1024]

components:
  renderer:
    component_type: "renderer"
    component_config:
      render_mode: "human"
      target_fps: 60

collect:
  teams: [scripted, scripted]
  total_episodes: 100000
  type_ratios:
    type1: 0.25
    type2: 0.25
    type3: 0.25
    type4: 0.25
  ship_count_ratios:
    "1v1": 0.25
    "2v2": 0.25
    "3v3": 0.25
    "4v4": 0.25
  output_dir: "data/bc_pretraining"
  num_workers: 12
  save_frequency: 256
  render_mode: "none"
  max_episode_length: 512
  random_action_prob: 0.05
  min_skill: 0.1
  max_skill: 1.0
  expert_ratio: 0.50 
  random_dist: "beta"
  
  massive:
    num_envs: 2048
    steps: 33554432
    batch_size: 2048
    buffer_steps: 512

train:
  run_collect: true
  run_world_model: true
  
  amp: true 
  compile: true
  # compile_mode: "max-autotune"
  compile_mode: "default"
  
  bc_data_path: data/bc_pretraining/aggregated_data.h5
  
  # Default Training Hyperparameters (can be overridden by model config)
  epochs: 1000
  batch_size: 32
  num_workers: 4
  learning_rate: 3.5e-5
  gradient_accumulation_steps: 8

# Model specific overrides come from defaults list 'model' group.
# See configs/model/*.yaml